<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="机器学习人工智能（Intelligent agents/systems）Learn/fit/train a model from data, then use it for prediction机器学习算法与计量模型一样都是统计模型，，其期望的预测错误＝Var(Y)+Bias+Var(f(x))
模型越复杂，r squre越大，拟合程度越高，但是随着模型复杂程度的增长，其variance会越来越大">
<meta property="og:type" content="article">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://yoursite.com/2017/04/06/机器学习/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="机器学习人工智能（Intelligent agents/systems）Learn/fit/train a model from data, then use it for prediction机器学习算法与计量模型一样都是统计模型，，其期望的预测错误＝Var(Y)+Bias+Var(f(x))
模型越复杂，r squre越大，拟合程度越高，但是随着模型复杂程度的增长，其variance会越来越大">
<meta property="og:image" content="http://yoursite.com/media/14914549059400/14914587579700.jpg">
<meta property="og:image" content="http://yoursite.com/media/14914549059400/14914588779914.jpg">
<meta property="og:image" content="http://yoursite.com/media/14914549059400/14914605597390.jpg">
<meta property="og:image" content="http://yoursite.com/media/14914549059400/14914607659562.jpg">
<meta property="og:image" content="http://yoursite.com/media/14914549059400/14914608004944.jpg">
<meta property="og:image" content="http://yoursite.com/media/14914549059400/14914611672451.jpg">
<meta property="og:image" content="http://yoursite.com/media/14914549059400/14914624334671.jpg">
<meta property="og:image" content="http://yoursite.com/media/14914549059400/14914627406002.jpg">
<meta property="og:image" content="http://yoursite.com/media/14914549059400/14914628542171.jpg">
<meta property="og:image" content="http://yoursite.com/media/14914549059400/14914629073509.jpg">
<meta property="og:image" content="http://yoursite.com/media/14914549059400/14914630637201.jpg">
<meta property="og:image" content="http://yoursite.com/media/14914549059400/14914634403002.jpg">
<meta property="og:image" content="http://yoursite.com/media/14914549059400/14914634904309.jpg">
<meta property="og:updated_time" content="2017-04-06T14:14:57.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Hexo">
<meta name="twitter:description" content="机器学习人工智能（Intelligent agents/systems）Learn/fit/train a model from data, then use it for prediction机器学习算法与计量模型一样都是统计模型，，其期望的预测错误＝Var(Y)+Bias+Var(f(x))
模型越复杂，r squre越大，拟合程度越高，但是随着模型复杂程度的增长，其variance会越来越大">
<meta name="twitter:image" content="http://yoursite.com/media/14914549059400/14914587579700.jpg">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-机器学习" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/04/06/机器学习/" class="article-date">
  <time datetime="2017-04-06T05:01:45.000Z" itemprop="datePublished">2017-04-06</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="机器学习"><a href="#机器学习" class="headerlink" title="机器学习"></a>机器学习</h1><h2 id="人工智能（Intelligent-agents-systems）"><a href="#人工智能（Intelligent-agents-systems）" class="headerlink" title="人工智能（Intelligent agents/systems）"></a>人工智能（Intelligent agents/systems）</h2><p>Learn/fit/train a model from data, then use it for prediction<br>机器学习算法与计量模型一样都是统计模型，，其期望的预测错误＝Var(Y)+Bias+Var(f(x))<br><img src="media/14914549059400/14914587579700.jpg" alt=""></p>
<p>模型越复杂，r squre越大，拟合程度越高，但是随着模型复杂程度的增长，其variance会越来越大。<br><img src="media/14914549059400/14914588779914.jpg" alt=""></p>
<p>所以机器学习与计量模型优化的目标不同，计量是提高计算的拟合度，但是机器学习是最小化整个EPE。<br>而且计量是用来解释的，希望关系的自变量p 越小越好，很显著，检验通过，并且可以定量的描述；机器学习是预测性的模型，提高预测的准确度。，最小化bias<br>找到比较的理论和因果关系图<br>may sacrifice theoretical accuracy for improved empirical precision<br>bias-variance tradeoff: minimize both bias and estimation variance<br>在机器学习里面你要用线性回归一般要加一些正则项。<br>集成模型一般会采用决策树来作为基础的learner</p>
<h3 id="knn-算法"><a href="#knn-算法" class="headerlink" title="knn 算法"></a>knn 算法</h3><p>当k的值变大的时候，曲线会变得平滑，当k取到所有点之和的时候，则会取到你集里面最多的那种点，因为随着k增大，会降低每个点的重要性。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">from sklearn.datasets import make_moons</div><div class="line">X,y=make_moons(n_sample=500,random_state=1),noise=0.3</div><div class="line">from sklearn.cross_validation import train_test_split</div><div class="line">XTrain,Xtest,yTrain,yTest=train_test_split(X,y,random_state=1,test_size=0.5)</div></pre></td></tr></table></figure>
<p><img src="media/14914549059400/14914605597390.jpg" alt=""></p>
<h3 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h3><p>通过正则化的方式，加一个惩罚，减少模型的复杂度。优化的不仅仅是殘差之和<br>L1就是拉索回归，L2是岭回归<br><img src="media/14914549059400/14914607659562.jpg" alt=""><br><img src="media/14914549059400/14914608004944.jpg" alt=""></p>
<h3 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h3><p>目前预测效果最好的是基于树的还有深度的，虽然预测效果好，但是无法解释，但是决策树解释性非常强，得到分类的时候可以判断他走了哪些路，Two pruning approaches－最大化墒的分叉<br>等于每一次分叉都是把点切开，这时候每次的选择都优先选择切分程度最好的线<br><img src="media/14914549059400/14914611672451.jpg" alt=""></p>
<p>当发现树过于复杂的时候就可以剪支叫预剪支，而后面再剪支叫做后剪支</p>
<h3 id="集成模型"><a href="#集成模型" class="headerlink" title="集成模型"></a>集成模型</h3><p>一类叫Bagging（随机森林）<br>一类叫Boosting(AdaBoost)<br>集成模型是把多个模型合起来，然后的话回归的时候可以做加权平均，分类的时候可以多数胜出。<br>sample里面有理论，想办法把模型合起来<br>Bagging (Bootstrap aggregating)用了非常强大的抽样方法<br><img src="media/14914549059400/14914624334671.jpg" alt=""></p>
<p>Random forests 引入了更大的随机性，他对于features也进行了随机抽样<br>所以单个的树会越弱（其实是单个模型越弱越好）<br><img src="media/14914549059400/14914627406002.jpg" alt=""></p>
<p>可以理解从单个模型来看，采样样本上过拟合，当将这些模型合起来的时候，整体的模型过拟合程度反而会减少。</p>
<h3 id="第二种集成策略叫做提升"><a href="#第二种集成策略叫做提升" class="headerlink" title="第二种集成策略叫做提升"></a>第二种集成策略叫做提升</h3><p>刚才的模型是没有顺序的，但是Boosting 模型之间有依赖关系。<br><img src="media/14914549059400/14914628542171.jpg" alt=""></p>
<p><img src="media/14914549059400/14914629073509.jpg" alt=""><br><strong>知错就改</strong>：会把分错的那些点的权重增大，所以在第二轮学习的时候，在计算的时候影响力更大。把更多的精力放在分错的点，再学习一个模型出来，一直学习出来一个优先顺序的模型，有一定的依赖关系。<br><img src="media/14914549059400/14914630637201.jpg" alt=""></p>
<p>boosting是从一个欠拟合的模型开始慢慢的把模型变成强的</p>
<h3 id="GBDT－xgboost-专注于集成学习"><a href="#GBDT－xgboost-专注于集成学习" class="headerlink" title="GBDT－xgboost(专注于集成学习)"></a>GBDT－xgboost(专注于集成学习)</h3><h3 id="模型评价"><a href="#模型评价" class="headerlink" title="模型评价"></a>模型评价</h3><p>数据量比较少的时候可以做cross-validation k-flod</p>
<p>把数据切成多少块，测试稳定性<br><img src="media/14914549059400/14914634403002.jpg" alt=""><br>二元分类的时候的分类指标 recall相当于查准率<br>f measure是precision和recall的调和平均数<br><img src="media/14914549059400/14914634904309.jpg" alt=""></p>
<p>AUC curve 中，有些分类器不仅仅会输出预测结果，还有一个概率，这时会有一个strench hold， 当高于这个值的时候，分类器会作为正类，而低于这个值的时候，会作为负类。可以描述分类器的全局的分类指标，而不仅仅是定义一个hold。就是取不同的hold的值的时候，不同的值<br>AUC 的值是与x轴围成的面积。<br>一般只适用于二元分类</p>
<h3 id="模型选择"><a href="#模型选择" class="headerlink" title="模型选择"></a>模型选择</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div></pre></td><td class="code"><pre><div class="line">print(__doc__)</div><div class="line"></div><div class="line"></div><div class="line"># Code source: Gaël Varoquaux</div><div class="line">#              Andreas Müller</div><div class="line"># Modified for documentation by Jaques Grobler</div><div class="line"># License: BSD 3 clause</div><div class="line"></div><div class="line">import numpy as np</div><div class="line">import matplotlib.pyplot as plt</div><div class="line">from matplotlib.colors import ListedColormap</div><div class="line">from sklearn.model_selection import train_test_split</div><div class="line">from sklearn.preprocessing import StandardScaler</div><div class="line">from sklearn.datasets import make_moons, make_circles, make_classification</div><div class="line">from sklearn.neural_network import MLPClassifier</div><div class="line">from sklearn.neighbors import KNeighborsClassifier</div><div class="line">from sklearn.svm import SVC</div><div class="line">from sklearn.gaussian_process import GaussianProcessClassifier</div><div class="line">from sklearn.gaussian_process.kernels import RBF</div><div class="line">from sklearn.tree import DecisionTreeClassifier</div><div class="line">from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier</div><div class="line">from sklearn.naive_bayes import GaussianNB</div><div class="line">from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis</div><div class="line"></div><div class="line">h = .02  # step size in the mesh</div><div class="line"></div><div class="line">names = [&quot;Nearest Neighbors&quot;, &quot;Linear SVM&quot;, &quot;RBF SVM&quot;, &quot;Gaussian Process&quot;,</div><div class="line">         &quot;Decision Tree&quot;, &quot;Random Forest&quot;, &quot;Neural Net&quot;, &quot;AdaBoost&quot;,</div><div class="line">         &quot;Naive Bayes&quot;, &quot;QDA&quot;]</div><div class="line"></div><div class="line">classifiers = [</div><div class="line">    KNeighborsClassifier(3),</div><div class="line">    SVC(kernel=&quot;linear&quot;, C=0.025),</div><div class="line">    SVC(gamma=2, C=1),</div><div class="line">    GaussianProcessClassifier(1.0 * RBF(1.0), warm_start=True),</div><div class="line">    DecisionTreeClassifier(max_depth=5),</div><div class="line">    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),</div><div class="line">    MLPClassifier(alpha=1),</div><div class="line">    AdaBoostClassifier(),</div><div class="line">    GaussianNB(),</div><div class="line">    QuadraticDiscriminantAnalysis()]</div><div class="line"></div><div class="line">iris = datasets.load_iris()</div><div class="line">X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.4, random_state=0)</div><div class="line">for name, clf in zip(names, classifiers):</div><div class="line">    clf.fit(X_train, y_train)</div><div class="line">    score = clf.score(X_test, y_test)</div><div class="line">    t=[name, score]</div></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/04/06/机器学习/" data-id="cj1778zdv0001t5pfooe8exaa" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2017/04/06/描述性统计/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          (no title)
        
      </div>
    </a>
  
  
    <a href="/2017/03/08/hah/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title"></div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/04/">April 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/03/">March 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/08/">August 2016</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2017/04/06/描述性统计/">(no title)</a>
          </li>
        
          <li>
            <a href="/2017/04/06/机器学习/">(no title)</a>
          </li>
        
          <li>
            <a href="/2017/03/08/hah/">(no title)</a>
          </li>
        
          <li>
            <a href="/2016/08/09/hello-world/">Hello World</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2017 John Doe<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>